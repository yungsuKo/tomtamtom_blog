---
title: 'Nextjs SEO 최적화하기'
date: 2024-08-25
desc: 검색결과에 상위 노출이 되기 위해 nextjs로 검색 엔진 최적화하는 방법에 대해서 소개합니다.
---

import Divider from '../../components/Divider.jsx';

# <b>TL:DR</b>

- Nextjs는 SSR 방식으로 검색 엔진 최적화를 할 수 있음.
- SSR이란 서버에서 웹페이지를 생성해 놓는 것을 의미함.
- SEO는 3가지 측면을 고려하여 개선할 수 있음.
- 개발 파트에서는 '기술'적인 부분을 개선할 수 있음.
- 그리고 이것은 구글이 작성된 글이 어떠한 내용인지 쉽고 빠르게 읽어갈 수 있도록 하는 것을 의미함.
- 이를 위해서 신경써야할 것은 아래와 같음.

  - Nextjs 렌더링 방식
  - Meta Tags(메타태그)
  - Sitemap (사이트맵)
  - robots.txt (로봇.txt)
  - JSON-LD 스키마 이용
  - Link Tags (링크 태그들)

<Divider />

## <b>SEO에서 SSR이 유리한 이유</b>

<br />

### <b>SEO 동작 과정 </b>

<br />

SEO의 동작 원리부터 설명하면 SSR이 어떤 이유에서 더 유리한지 이해할 수 있을 것 같다.<br/>

1. 크롤링 (Crawling)

   - 목적<br />웹 크롤러(일명 "구글봇")가 웹사이트를 방문하여 페이지의 콘텐츠를
     수집하는 과정이다. 크롤러는 페이지의 HTML, 이미지, CSS, 자바스크립트 등
     다양한 파일을 다운로드하고, 페이지에 포함된 링크를 따라 다른 페이지로
     이동한다.
   - 작동 방식:<br />
     구글봇은 주기적으로 인터넷을 탐색하며 새로운 페이지와 업데이트된 콘텐츠를 찾는다.
     사이트맵(XML 형식)과 robots.txt 파일을 참조하여 크롤러가 어떤 페이지를 크롤링할지 결정한다.<br/>

2. 인덱싱 (Indexing)<br/>

   - 목적<br/>크롤링된 페이지의 내용을 분석하고, 이를 구글의 데이터베이스에 저장하는 과정이다. <br/>

   - 작동 방식<br/>
     구글봇이 수집한 HTML 파일을 분석하여 페이지의 텍스트, 이미지, 메타데이터, 키워드 등을 추출한다.
     이 데이터는 구글의 인덱스에 저장되며, 페이지가 어떤 주제를 다루고 있는지, 검색 쿼리에 적합한지 등을 판단하는 데 사용된다.
     구글은 또한 페이지의 구조, URL 구조, 내부 링크 등을 분석하여 페이지 간의 관계를 파악한다.

3. 순위 결정 (Ranking) <br/>

   - 목적
     사용자가 검색 쿼리를 입력했을 때, 그에 맞는 가장 적합한 페이지를 순서대로 제공하는 과정이다.<br/>

   - 작동 방식<br/>
     알고리즘 평가: 구글은 200개 이상의 요소를 평가하여 페이지의 순위를 결정한다. 주요 요소는 다음과 같다:<br/> - 키워드 적합성: 사용자가 입력한 검색어와 페이지 콘텐츠의 관련성. - 페이지 권위: 외부 링크(백링크)의 수와 품질을 통해 측정됩니다. - 사용자 경험: 페이지 로딩 속도, 모바일 친화성, 사용자 체류 시간 등이 영향을 미칩니다. - 콘텐츠 품질: 콘텐츠의 유용성, 정확성, 최신성 등이 고려됩니다. - 기타: 메타 태그, 구조화된 데이터, 내부 링크 구조 등이 포함됩니다. - 머신 러닝 및 AI: 구글은 AI를 사용하여 검색 쿼리와 페이지 간의 복잡한 관계를 이해하고, 사용자에게 더 적합한 결과를 제공합니다.
     <br />

### <b>SSR과 CSR의 역사</b>

<br />
SSR (Server-Side Rendering) 기술은 웹 페이지를 서버에서 렌더링하여 클라이언트에 전달하는
방식이다. 이 방식은 브라우저에서 자바스크립트가 실행되기 전에 완전히 렌더링된 HTML을
제공하므로 초기 로드 시간과 SEO(검색 엔진 최적화)에 유리하다. 이는 오래전부터 존재했던
방식으로, 초기의 웹 애플리케이션들은 주로 SSR 방식으로 구현되었다.

전통적인 SSR 방식은 페이지 간 전환이 있을 때마다 서버로부터 새로운 HTML을 받아오는 방식이었기 때문에 사용자 경험이 상대적으로 느리고 부드럽지 않았다.
이에 따라, React는 Facebook에서 2013년에 개발되었으며,
컴포넌트 기반의 UI 라이브러리로 사용자 인터페이스 구축을 단순화하고 효율적으로 만들기 위해 설계되었다.
React의 가상 DOM(Virtual DOM)을 활용한 효율적인 렌더링 방식은 빠른 사용자 인터페이스를 제공하고,
UI의 상태 관리와 업데이트를 쉽게 할 수 있게 했다.
하지만 React 기반 SPA는 초기 로드 시 콘텐츠가 자바스크립트로 렌더링되기 때문에, 검색 엔진이 페이지 콘텐츠를 크롤링하는 데 어려움을 겪을 수 있다.

React의 한계점을 보완하기 위해 Next.js가 등장했다.
Next.js는 React 기반의 프레임워크로, SSR과 SSG(Static Site Generation) 등의 다양한 렌더링 방식을
지원하여 React의 단점을 보완한다.

<br />
<Divider />

## <b>Nextjs에서 SEO를 개선하기 위해서는?</b>

### <b>1. 렌더링 방식 : SSR vs SSG</b>

SSR vs SSG: SEO 관점에서 비교

SSR: 실시간 데이터가 중요하거나, 사용자별로 다른 콘텐츠를 보여줘야 하는 경우에 SEO에 더 유리하다. 이는 동적인 페이지에서 검색 엔진이 최신 상태의 콘텐츠를 크롤링할 수 있게 된다.

SSG: 콘텐츠가 자주 변하지 않고, 페이지 로딩 속도가 중요한 경우에 SEO에 더 유리하다. 정적 콘텐츠의 경우 SSG가 더 빠른 로딩 시간을 제공하며, 이는 검색 엔진에서 긍정적으로 반영된다.

### <b>2. Meta Tags 메타 태그</b>

메타태그는 웹 페이지의 정보를 검색 엔진과 사용자에게 전달하는 역할을 한다.
이 태그들은 페이지의 제목, 설명, 키워드 등을 명시하며, 검색 엔진이 페이지를 더 잘 이해하고, 사용자에게 올바른 정보를 제공할 수 있게 도와준다.

```html title="Meta tags 종류"
<!-- 기본 세팅 -->
<title>웹사이트 타이틀</title>
<meta name="description" content="웹페이지 상세 설명" />
<meta name="keywords" content="키워드 여러 개 나열" />
<meta name="robots" content="index, follow" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta charset="utf-8" />
<!-- opengrapgh -->
<meta property="og:site_name" content="사이트 이름" />
<meta property="og:locale" content="ko_KR" />
<meta property="og:title" content="웹사이트 타이틀" />
<meta property="og:description" content="웹사이트 상세 설명" />
<meta property="og:type" content="website" />
<meta property="og:url" content="웹사이트 url 주소" />
<meta property="og:image" content="웹사이트 이미지 url 주소" />
<meta property="og:image:alt" content="웹사이트 이미지 alt 텍스트" />
<meta property="og:image:type" content="image/png" />
<meta property="og:image:width" content="1200" />
<meta property="og:image:height" content="630" />
<!-- article tags -->
<meta property="article:published_time" content="2024-01-14T11:35:00+07:00" />
<meta property="article:modified_time" content="2024-01-14T11:35:00+07:00" />
<meta property="article:author" content="https://www.linkedin.com/in/myname" />
<!-- twitter tags -->
<meta name="twitter:card" content="대형 이미지에 대한 요약 설명" />
<meta name="twitter:site" content="@mycodings" />
<meta name="twitter:creator" content="@mycodings" />
<meta name="twitter:title" content="웹사이트 제목" />
<meta name="twitter:description" content="웹사이트 상세 설명" />
<meta name="twitter:image" content="웹사이트 이미지 url 주소" />
```

### <b>3. Sitemap 사이트맵</b>

사이트맵은 웹사이트의 페이지 구조를 나열한 파일로, 검색 엔진이 웹사이트를 효율적으로 크롤링하고 인덱싱할 수 있게 도와준다.
특히 대규모 웹사이트나 동적 콘텐츠를 많이 포함한 사이트에서는 사이트맵이 필수적이다.

```
npm install next-sitemap
npx next-sitemap
```

### <b>4. robots.txt </b>

robots.txt 파일은 검색 엔진 크롤러가 어떤 페이지를 크롤링할 수 있는지 또는 없는지를 지정한다.
잘 설계된 robots.txt 파일은 검색 엔진이 중요하지 않은 페이지를 크롤링하는 것을 방지하여 크롤링 예산을 최적화할 수 있습니다.

### <b>5. link tags </b>

JSON-LD는 구조화된 데이터를 페이지에 추가하여 검색 엔진이 페이지 내용을 더 잘 이해하도록 돕는 방식이다.
이를 통해 검색 결과에서 리치 스니펫(예: 리뷰 별점, 가격, 이벤트 정보 등)으로 표시될 가능성이 높아져 CTR(클릭률)이 상승할 수 있다.

```
<link rel="canonical" href="페이지의 url"/>
<link rel="alternate" href="페이지의 url" hrefLang="ko_KR"/>
<link rel="icon" href="아이콘 url" type="image/x-icon"/>
<link rel="apple-touch-icon" href="아이콘 url"/>
<link rel="manifest" href="manifest url"/>
```

<Divider />
## <b>결론</b>

Next.js를 활용한 SEO 최적화는 단순히 검색 엔진에서 더 높은 순위를 차지하는 것 이상을 의미한다.
이는 궁극적으로 비즈니스 성과와 직결된다.
메타태그와 사이트맵을 통한 검색 엔진의 효율적인 크롤링, JSON-LD 스키마를 통한 리치 스니펫 노출, 그리고 서버 사이드 렌더링(SSR)으로 보장된 빠른 페이지 로딩 속도는 사용자 경험을 크게 개선하며,
이는 높은 전환율과 고객 만족도로 이어진다.

빠르고 사용자 친화적인 웹사이트는 더 많은 트래픽을 유도하며, 이는 곧 더 많은 리드와 매출 증가로 연결된다.
특히, 검색 엔진 최적화된 페이지는 장기적으로 안정적인 유기적 트래픽을 확보할 수 있어, 광고비를 절감하면서도 지속적인 비즈니스 성장을 지원할 수 있다.

결국, Next.js를 통해 잘 최적화된 웹사이트는 단순한 기술적 우위를 넘어, 기업의 온라인 경쟁력을 강화하고 수익성을 높이는 강력한 도구가 된다.
SEO 최적화는 이제 선택이 아닌 필수이며, 이를 전략적으로 활용하는 기업은 디지털 시대에서 확실한 비즈니스 성과를 거둘 수 있다.

## <b>참고 자료</b>

https://mycodings.fly.dev/blog/2024-01-14-all-about-nextjs-seo
https://velog.io/@yukimiau/SSR%EC%99%80-Next.js-%EA%B7%B8%EB%A6%AC%EA%B3%A0-SEO
